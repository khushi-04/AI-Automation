{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0ecbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hexathello.aiPlayers as aiPlayers\n",
    "import hexathello.AutoPlayer as autoPlayer\n",
    "import hexathello.Engine as engine\n",
    "import hexathello.history as history\n",
    "import hexathello.jable as jable\n",
    "import hexathello.printing as printing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "\n",
    "# -- Settings\n",
    "game_size: int = 5\n",
    "player_count: int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5b35b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_matchups.json']\n"
     ]
    }
   ],
   "source": [
    "matchup_dir = \"data/history/matchups\"\n",
    "matchup_files = [f for f in listdir(matchup_dir) if f.endswith(\".json\")]\n",
    "print(matchup_files)\n",
    "\n",
    "agent_ids_v1 = [\n",
    "    \"1x720_total720_size5_players2_v1\",\n",
    "    \"2x360_total720_size5_players2_v1\",\n",
    "    \"3x240_total720_size5_players2_v1\",\n",
    "    \"4x180_total720_size5_players2_v1\",\n",
    "    \"5x144_total720_size5_players2_v1\",\n",
    "    \"6x120_total720_size5_players2_v1\",\n",
    "    \"7x102_total714_size5_players2_v1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f30778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Retraining agent: 1x720_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5867\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8248\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6348\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4585\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3419\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2544\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2436\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1510\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1277\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1202\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\1x720_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 2x360_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5182\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9905\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8209\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6320\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5150\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4526\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3742\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2996\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2643\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1992\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\2x360_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 3x240_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5271\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1957\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0641\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9733\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8613\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8038\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7398\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6507\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6426\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5750\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\3x240_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 4x180_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4744\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3248\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2713\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1974\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1299\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1181\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0855\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0477\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0018\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9628\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\4x180_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 5x144_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5908\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4751\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4156\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3661\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3174\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3283\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2515\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2812\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2289\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2390\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\5x144_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 6x120_total720_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5741\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5001\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4815\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4358\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4540\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4184\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3925\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3984\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3670\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3950\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\6x120_total720_size5_players2_v2.keras\n",
      "\n",
      " Retraining agent: 7x102_total714_size5_players2_v1\n",
      "Epoch 1/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6443\n",
      "Epoch 2/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5410\n",
      "Epoch 3/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5061\n",
      "Epoch 4/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5211\n",
      "Epoch 5/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4869\n",
      "Epoch 6/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4844\n",
      "Epoch 7/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4869\n",
      "Epoch 8/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4635\n",
      "Epoch 9/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4518\n",
      "Epoch 10/10\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4357\n",
      "Retrained and saved model as data\\ai\\vary_dimensions\\7x102_total714_size5_players2_v2.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ai_id_v1 in agent_ids_v1:\n",
    "    print(f\"\\n Retraining agent: {ai_id_v1}\")\n",
    "\n",
    "    training_pov = []\n",
    "\n",
    "    relevant_files = [f for f in matchup_files if ai_id_v1 in f]\n",
    "\n",
    "    match_frames = []\n",
    "    for fname in matchup_files:\n",
    "        full_path = join(matchup_dir, fname)\n",
    "        \n",
    "        history_fromDisk: jable.JyFrame = jable.read_file(\n",
    "            full_path\n",
    "        )\n",
    "    \n",
    "        history_decoded: jable.JyFrame = history.history_fromInt(\n",
    "            history_fromDisk\n",
    "        )\n",
    "    \n",
    "        if len(history_decoded) < 20:\n",
    "            print('skipping')\n",
    "            continue\n",
    "    \n",
    "    \n",
    "        povHistory: jable.JyFrame = history.povHistory_from_literalHistory(\n",
    "            history_decoded\n",
    "        )\n",
    "\n",
    "        del history_decoded\n",
    "        del history_fromDisk\n",
    "\n",
    "        match_frames.append(povHistory)\n",
    "\n",
    "\n",
    "        input_size: int = len(povHistory[0, 'board_state'])\n",
    "        output_size: int = len(povHistory[0, 'player_action'])\n",
    "\n",
    "    keras_path_v1 = join(\"data\", \"ai\", \"vary_dimensions\", f\"{ai_id_v1}.keras\")\n",
    "    if not path.isfile(keras_path_v1):\n",
    "        print(f\"Model not found at {keras_path_v1}\")\n",
    "        continue\n",
    "\n",
    "    brain_model = tf.keras.models.load_model(keras_path_v1)\n",
    "    ai_id_v2 = ai_id_v1.replace(\"v1\", \"v2\")\n",
    "    keras_path_v2 = join(\"data\", \"ai\", \"vary_dimensions\", f\"{ai_id_v2}.keras\")\n",
    "    os.makedirs(os.path.dirname(keras_path_v2), exist_ok=True)\n",
    "\n",
    "    # Init updated agent\n",
    "    ai_agent = aiPlayers.KerasHexAgent(\n",
    "        size=game_size,\n",
    "        player_count=player_count,\n",
    "        brain=brain_model,\n",
    "        player_id=None,\n",
    "        ai_id=ai_id_v2\n",
    "    )\n",
    "\n",
    "    # Save only the improved model under the v2 name\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=keras_path_v2,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    training_pov_frame: jable.JyFrame = jable.JyFrame(training_pov)\n",
    "\n",
    "    # Train with only relevant matches\n",
    "    for povHistory in match_frames:\n",
    "        ai_agent.train(\n",
    "            game_history=povHistory,\n",
    "            epochs=10,\n",
    "            callbacks=[checkpoint_cb]\n",
    "        )\n",
    "\n",
    "    print(f\"Retrained and saved model as {keras_path_v2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
